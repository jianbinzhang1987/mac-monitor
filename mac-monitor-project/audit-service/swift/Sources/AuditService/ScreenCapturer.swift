import Foundation
import ScreenCaptureKit
import Vision
import CoreGraphics
import CoreImage
import CoreVideo
import VideoToolbox
import AppKit

// å®šä¹‰åè®®ä»¥å®‰å…¨è®¿é—®æ–°ç‰ˆ macOS å±æ€§ï¼Œè§£å†³ç¼–è¯‘ SDK è¿‡ä½å’Œ KVC ä¸å…¼å®¹å¯¼è‡´çš„å´©æºƒé—®é¢˜
@objc protocol SCStreamConfigurationPrivate {
    @objc optional func setShowsRecordingIndicator(_ show: Bool)
    @objc optional func setExcludesCurrentProcess(_ exclude: Bool)
}

// é…ç½®ç»“æ„
struct CaptureConfig: Codable {
    struct CaptureSettings: Codable {
        let fullscreen_enabled: Bool
        let window_enabled: Bool
        let capture_interval: TimeInterval
        let window_scan_interval: TimeInterval
    }

    struct FilterSettings: Codable {
        let min_window_width: CGFloat
        let min_window_height: CGFloat
        let one_window_per_app: Bool
    }

    struct OCRSettings: Codable {
        let enabled: Bool
        let language_correction: Bool
        let recognition_level: String
        let redaction_enabled: Bool
        let sensitive_keywords: [String]
    }

    struct TargetApp: Codable {
        let name: String
        let bundle_id: String
        let enabled: Bool
    }

    let capture: CaptureSettings
    let filter: FilterSettings
    let ocr: OCRSettings
    let target_apps: [TargetApp]
}

@available(macOS 12.3, *)
class ScreenCapturer: NSObject, SCStreamOutput, SCStreamDelegate {
    static let shared = ScreenCapturer()

    // å…¨å±æˆªå›¾ stream
    private var displayStream: SCStream?

    // ä¸Šæ¬¡å¤„ç†çš„æ—¶é—´è®°å½•
    private var lastCaptureTime: Date = Date.distantPast
    private var lastWindowProcessTime: [String: Date] = [:]

    private let videoSampleBufferQueue = DispatchQueue(label: "com.macmonitor.VideoSampleBufferQueue")


    // å®šæ—¶å™¨ç”¨äºåŠ¨æ€çª—å£ç›‘æ§
    private var windowScanTimer: Timer?

    // é…ç½®å‚æ•° (ä»é…ç½®æ–‡ä»¶åŠ è½½)
    private var config: CaptureConfig?
    private var captureInterval: TimeInterval = 10.0
    private var windowScanInterval: TimeInterval = 30.0
    private var minWindowWidth: CGFloat = 400
    private var minWindowHeight: CGFloat = 300
    private var targetApps: [String] = []
    var redactionEnabled: Bool = true // æ”¹ä¸º internal æ–¹ä¾¿ä¿®æ”¹
    private var sensitiveKeywords: [String] = []

    // çª—å£ä¿¡æ¯ (ä»…ç”¨äºåæ ‡è£å‰ªï¼Œä¸å†æŒæœ‰æµ)
    struct WindowInfo {
        let appName: String
        let bundleId: String
        let windowID: CGWindowID
        let frame: CGRect
    }

    // æ´»è·ƒçš„ç›®æ ‡çª—å£åˆ—è¡¨
    private var activeWindows: [String: WindowInfo] = [:]

    // å±å¹•é«˜åº¦ (ç”¨äºåæ ‡è½¬æ¢)
    private var screenHeight: Int = 1080


    // OCR è¯·æ±‚
    private lazy var ocrRequest: VNRecognizeTextRequest = {
        let request = VNRecognizeTextRequest()
        request.recognitionLevel = .accurate
        request.usesLanguageCorrection = true

        // æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æ··åˆè¯†åˆ«
        // macOS 13.0+ æ”¯æŒç®€ä½“ä¸­æ–‡(zh-Hans)å’Œç¹ä½“ä¸­æ–‡(zh-Hant)
        if #available(macOS 13.0, *) {
            request.recognitionLanguages = ["zh-Hans", "zh-Hant", "en-US"]
        } else {
            // macOS 12.x åªæ”¯æŒè‹±æ–‡
            request.recognitionLanguages = ["en-US"]
        }

        // è‡ªåŠ¨æ£€æµ‹è¯­è¨€(å¦‚æœç³»ç»Ÿæ”¯æŒ)
        request.automaticallyDetectsLanguage = true

        return request
    }()

    override init() {
        super.init()
        loadConfig()
    }

    private func loadConfig() {
        let configPath = "/Users/adolf/Desktop/code/clash/mac-monitor-project/audit-service/config.json"

        guard let data = try? Data(contentsOf: URL(fileURLWithPath: configPath)) else {
            print("âš ï¸ Config file not found, using defaults")
            return
        }

        do {
            let decoder = JSONDecoder()
            config = try decoder.decode(CaptureConfig.self, from: data)

            // åº”ç”¨é…ç½®
            if let cfg = config {
                captureInterval = cfg.capture.capture_interval
                windowScanInterval = cfg.capture.window_scan_interval
                minWindowWidth = cfg.filter.min_window_width
                minWindowHeight = cfg.filter.min_window_height

                // åŠ è½½è„±æ•é…ç½®
                redactionEnabled = cfg.ocr.redaction_enabled
                sensitiveKeywords = cfg.ocr.sensitive_keywords

                // æå–å¯ç”¨çš„ç›®æ ‡åº”ç”¨
                targetApps = cfg.target_apps
                    .filter { $0.enabled }
                    .flatMap { [$0.name, $0.bundle_id] }

                print("âœ… Config loaded: \(targetApps.count/2) target apps enabled")
            }
        } catch {
            print("âŒ Failed to parse config: \(error)")
        }
    }

    func start() {
        print("ğŸ“¸ ScreenCapturer: Starting...")

        // 1. æ£€æŸ¥æƒé™
        if !CGPreflightScreenCaptureAccess() {
             print("âš ï¸ Screen recording permission not granted! Attempting to request...")
             if !CGRequestScreenCaptureAccess() {
                 print("âŒ Permission denied.")
                 return
             }
        }

        // 2. è·å–å¯åˆ†äº«çš„å†…å®¹
        Task {
            do {
                let content = try await SCShareableContent.current
                guard let display = content.displays.first else {
                    print("âŒ No display found")
                    return
                }

                // å¯åŠ¨å…¨å±æˆªå›¾
                self.startDisplayStream(display: display)

                // å¯åŠ¨ç‰¹å®šåº”ç”¨çª—å£æˆªå›¾
                self.startWindowStreams(content: content)

                // å¯åŠ¨å®šæ—¶æ‰«ææ–°çª—å£
                self.startWindowScanTimer()

            } catch {
                print("âŒ Failed to get shareable content: \(error)")
            }
        }
    }

    private func startWindowScanTimer() {
        windowScanTimer = Timer.scheduledTimer(withTimeInterval: windowScanInterval, repeats: true) { [weak self] _ in
            self?.scanForNewWindows()
        }
        print("â° Window scan timer started (interval: \(windowScanInterval)s)")
    }

    private func scanForNewWindows() {
        Task {
            do {
                let content = try await SCShareableContent.current
                print("ğŸ” Scanning for new windows...")
                await self.updateWindowStreams(content: content)
            } catch {
                print("âŒ Failed to scan windows: \(error)")
            }
        }
    }

    private func updateWindowStreams(content: SCShareableContent) async {
        var currentWindowIDs = Set<String>()

        // æ›´æ–°å±å¹•é«˜åº¦ï¼Œä¾›å‚è€ƒ
        if let display = content.displays.first {
            self.screenHeight = display.height
        }

        // 1. æ‰«æå¹¶æ›´æ–°æ´»è·ƒçª—å£ä¿¡æ¯
        for window in content.windows {
            guard let app = window.owningApplication else { continue }

            let appName = app.applicationName
            let bundleId = app.bundleIdentifier

            // æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡åº”ç”¨
            let isTargetApp = targetApps.contains { target in
                return appName.lowercased().contains(target.lowercased()) ||
                       bundleId.lowercased().contains(target.lowercased())
            }

            guard isTargetApp else { continue }

            // çª—å£å°ºå¯¸è¿‡æ»¤
            if window.frame.width < minWindowWidth || window.frame.height < minWindowHeight {
                continue
            }

            // è¿‡æ»¤æ— æ•ˆçª—å£ (ä¾‹å¦‚æœ€å°åŒ–æˆ–éšè—çš„çª—å£å¾€å¾€æœ‰å¥‡æ€ªçš„åæ ‡)
            if window.frame.origin.x.isNaN || window.frame.origin.y.isNaN { continue }

            // æ¯åº”ç”¨å•çª—å£ç­–ç•¥: æ£€æŸ¥è¯¥åº”ç”¨æ˜¯å¦å·²è®°å½•äº†çª—å£
            let hasAppWindow = currentWindowIDs.contains { key in
                return key.starts(with: bundleId)
            }
            if hasAppWindow {
                continue
            }

            let streamKey = "\(bundleId)_\(window.windowID)"
            currentWindowIDs.insert(streamKey)

            // æ›´æ–°çª—å£ä¿¡æ¯ (ä¸»è¦æ˜¯ Frame å˜åŒ–)
            let info = WindowInfo(
                appName: appName,
                bundleId: bundleId,
                windowID: window.windowID,
                frame: window.frame
            )

            if activeWindows[streamKey] == nil {
                print("  âœ¨ Target window detected: \(appName) (\(bundleId)) Frame: \(window.frame)")
            }
            activeWindows[streamKey] = info
        }

        // 2. æ¸…ç†å·²å…³é—­çª—å£
        let windowsToRemove = activeWindows.keys.filter { !currentWindowIDs.contains($0) }
        for key in windowsToRemove {
            if let info = activeWindows[key] {
                print("  ğŸ—‘ Target window closed: \(info.appName)")
            }
            activeWindows.removeValue(forKey: key)
            lastWindowProcessTime.removeValue(forKey: key)
        }
    }

    // ç§»é™¤ createWindowStreamï¼Œæ”¹ä¸ºå…¨å±è£å‰ªæ–¹æ¡ˆï¼Œä¸å†å•ç‹¬åˆ›å»ºçª—å£æµ

    private func startDisplayStream(display: SCDisplay) {
        print("ğŸ–¥ Starting full screen capture stream...")
        let filter = SCContentFilter(display: display, excludingWindows: [])

        let config = SCStreamConfiguration()
        config.width = display.width
        config.height = display.height
        config.pixelFormat = kCVPixelFormatType_32BGRA
        config.minimumFrameInterval = CMTime(value: 1, timescale: 1)
        config.queueDepth = 5

        // è¿›ä¸€æ­¥å‡å°‘æ„ŸçŸ¥ï¼šéšè—å…‰æ ‡ï¼Œæ’é™¤è‡ªèº«è¿›ç¨‹
        config.showsCursor = false

        // ä½¿ç”¨åè®®æ˜ å°„å®‰å…¨è®¾ç½®å±æ€§ï¼Œé¿å…ç¼–è¯‘é”™è¯¯å’Œè¿è¡Œæ—¶å´©æºƒ
        if let privateConfig = config as AnyObject as? SCStreamConfigurationPrivate {
            privateConfig.setExcludesCurrentProcess?(true)
            privateConfig.setShowsRecordingIndicator?(false)
        }

        do {
            displayStream = SCStream(filter: filter, configuration: config, delegate: self)
            try displayStream?.addStreamOutput(self, type: .screen, sampleHandlerQueue: videoSampleBufferQueue)

            displayStream?.startCapture { error in
                if let error = error {
                    print("âŒ Failed to start display capture: \(error)")
                } else {
                    print("âœ… Display capture stream started")
                }
            }
        } catch {
            print("âŒ Error creating display stream: \(error)")
        }
    }

    private func startWindowStreams(content: SCShareableContent) {
        print("ğŸªŸ Starting window capture streams for target apps...")

        // ä½¿ç”¨æ–°çš„ç»Ÿä¸€æ–¹æ³•
        Task {
            await updateWindowStreams(content: content)
        }
    }

    func stop() {
        // åœæ­¢å®šæ—¶å™¨
        windowScanTimer?.invalidate()
        windowScanTimer = nil

        // åœæ­¢å…¨å±æˆªå›¾
        displayStream?.stopCapture()
        displayStream = nil

        // æ¸…ç†çŠ¶æ€
        activeWindows.removeAll()
        lastWindowProcessTime.removeAll()

        print("ğŸ›‘ ScreenCapturer stopped")
    }

    // MARK: - SCStreamOutput

    func stream(_ stream: SCStream, didOutputSampleBuffer sampleBuffer: CMSampleBuffer, of type: SCStreamOutputType) {
        guard type == .screen else { return }

        // æˆ‘ä»¬ç°åœ¨åªå¤„ç† displayStream
        guard stream === displayStream else { return }

        let now = Date()

        // 1. å…¨å±æˆªå›¾é¢‘ç‡æ§åˆ¶
        if now.timeIntervalSince(lastCaptureTime) >= captureInterval {
            lastCaptureTime = now
            processFrame(sampleBuffer: sampleBuffer, captureType: "fullscreen", windowInfo: nil)
        }

        // 2. è™šæ‹Ÿçª—å£æˆªå›¾ (ä»å…¨å±æµè£å‰ª)
        processVirtualWindows(sampleBuffer: sampleBuffer)
    }

    private func processVirtualWindows(sampleBuffer: CMSampleBuffer) {
        guard !activeWindows.isEmpty else { return }
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }

        // é”å®šåŸºåœ°å€ä»¥è¯»å–å…¨å±å°ºå¯¸
        CVPixelBufferLockBaseAddress(pixelBuffer, .readOnly)
        let fullWidth = CGFloat(CVPixelBufferGetWidth(pixelBuffer))
        let fullHeight = CGFloat(CVPixelBufferGetHeight(pixelBuffer))
        CVPixelBufferUnlockBaseAddress(pixelBuffer, .readOnly)

        let now = Date()

        for (key, info) in activeWindows {
            // é¢‘ç‡æ§åˆ¶
            let lastTime = lastWindowProcessTime[key] ?? Date.distantPast
            if now.timeIntervalSince(lastTime) < captureInterval { continue }

            // ç²¾å‡†è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ (Retina å¤„ç†)
            // ä½¿ç”¨ç³»ç»Ÿä¸»å±å¹•çš„ç¼©æ”¾ç³»æ•°ï¼Œè¿™æ˜¯æœ€å¯é çš„æ–¹æ³•
            let scale = NSScreen.main?.backingScaleFactor ?? (fullWidth > 2000 ? 2.0 : 1.0)

            // è£å‰ªåçš„çª—å£ (åƒç´ åæ ‡)
            let x = info.frame.origin.x * scale
            let y = info.frame.origin.y * scale
            let w = info.frame.width * scale
            let h = info.frame.height * scale
            let pixelFrame = CGRect(x: x, y: y, width: w, height: h)

            let intersectRect = pixelFrame.intersection(CGRect(x: 0, y: 0, width: fullWidth, height: fullHeight))

            if intersectRect.width < 50 || intersectRect.height < 50 { continue }

            lastWindowProcessTime[key] = now

            // å¤„ç†è£å‰ªåçš„çª—å£
            processFrame(sampleBuffer: sampleBuffer, captureType: "window[\(info.appName)]", windowInfo: info, scale: scale)
        }
    }

    private func processFrame(sampleBuffer: CMSampleBuffer, captureType: String, windowInfo: WindowInfo?, scale: CGFloat = 1.0) {
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }

        CVPixelBufferLockBaseAddress(pixelBuffer, .readOnly)
        defer { CVPixelBufferUnlockBaseAddress(pixelBuffer, .readOnly) }

        let baseAddress = CVPixelBufferGetBaseAddress(pixelBuffer)
        let fullWidth = CVPixelBufferGetWidth(pixelBuffer)
        let fullHeight = CVPixelBufferGetHeight(pixelBuffer)
        let bytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer)

        guard let addr = baseAddress else { return }

        // å‡†å¤‡æ•°æ®ç»™ Rust å’Œ OCR
        // å¦‚æœæ˜¯å…¨å±ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹ buffer
        // å¦‚æœæ˜¯çª—å£ï¼Œæˆ‘ä»¬éœ€è¦æ‹·è´å‡º ROI (Region of Interest)

        var targetPtr = addr
        var targetWidth = UInt32(fullWidth)
        var targetHeight = UInt32(fullHeight)
        var targetData: Data? = nil // ç”¨äºä¿æŒæ‹·è´æ•°æ®çš„ç”Ÿå‘½å‘¨æœŸ

        if let info = windowInfo {
            // æ‰§è¡Œè£å‰ªæ‹·è´ (æ³¨æ„ï¼šinfo.frame æ˜¯ç‚¹åæ ‡ï¼Œå¿…é¡»è½¬æ¢ä¸ºåƒç´ åæ ‡è¿›è¡Œç‰©ç†è£å‰ª)
            let x = Int(max(0, info.frame.origin.x * scale))
            let y = Int(max(0, info.frame.origin.y * scale))
            let w = Int(min(CGFloat(fullWidth) - CGFloat(x), info.frame.width * scale))
            let h = Int(min(CGFloat(fullHeight) - CGFloat(y), info.frame.height * scale))

            if w <= 0 || h <= 0 { return }

            targetWidth = UInt32(w)
            targetHeight = UInt32(h)

            // åˆ›å»ºç´§å‡‘çš„ buffer (bytesPerRow = w * 4)
            let newBytesPerRow = w * 4
            var newData = Data(count: h * newBytesPerRow)

            newData.withUnsafeMutableBytes { destBytes in
                guard let destBase = destBytes.baseAddress else { return }
                let srcRaw = addr.assumingMemoryBound(to: UInt8.self)

                for row in 0..<h {
                    let srcOffset = (y + row) * bytesPerRow + (x * 4)
                    let dstOffset = row * newBytesPerRow

                    // æ‹·è´ä¸€è¡Œ
                    destBase.advanced(by: dstOffset).copyMemory(
                        from: srcRaw.advanced(by: srcOffset),
                        byteCount: w * 4
                    )
                }
            }

            targetData = newData
            targetData?.withUnsafeBytes { ptr in
                if let base = ptr.baseAddress {
                    targetPtr = UnsafeMutableRawPointer(mutating: base)
                }
            }
        }

        // 2. æ‰§è¡Œ OCR (ä½¿ç”¨ Vision)
        // Vision å¯ä»¥å¤„ç†å…¨å±å›¾åƒå¹¶æŒ‡å®š regionOfInterestï¼Œæ¯”ç‰©ç†æ‹·è´æ›´å¿«
        // ä½†ä¸ºäº†ä»£ç å¤ç”¨ï¼Œå¦‚æœå·²ç»æ‹·è´äº† crop æ•°æ®ï¼Œç›´æ¥ç”¨ crop æ•°æ®åš OCR ä¹Ÿå¯ä»¥
        // è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ç”¨è£å‰ªåçš„æ•°æ®ç”Ÿæˆ CIImage (å¦‚æœ targetData å­˜åœ¨)
        // æˆ–è€…å¯¹å…¨å±ä½¿ç”¨ ROIã€‚ä¸ºäº†é€»è¾‘ç»Ÿä¸€ï¼Œæˆ‘ä»¬ç”¨ targetPtr åˆ›å»º CIImageã€‚

        let ciImage: CIImage
        if let data = targetData {
             // ä»è£å‰ªåçš„æ•°æ®åˆ›å»º CIImage
             let size = CGSize(width: Int(targetWidth), height: Int(targetHeight))
             ciImage = CIImage(bitmapData: data, bytesPerRow: Int(targetWidth) * 4, size: size, format: .BGRA8, colorSpace: nil)
        } else {
             ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        }

        let handler = VNImageRequestHandler(ciImage: ciImage, options: [:])

        var ocrText = ""
        var isSensitiveFrame = false
        var redactionLabels = ""
        do {
            try handler.perform([ocrRequest])
            if let observations = ocrRequest.results {
                // 1. è„±æ•æ£€æµ‹
                if redactionEnabled {
                    let targets = SensitiveInfoDetector.detect(
                        in: observations,
                        imageSize: CGSize(width: Int(targetWidth), height: Int(targetHeight)),
                        customKeywords: sensitiveKeywords
                    )

                    if !targets.isEmpty {
                        isSensitiveFrame = true
                        // æå–å”¯ä¸€çš„è„±æ•æ ‡ç­¾
                        redactionLabels = Array(Set(targets.map { $0.label })).joined(separator: ",")
                        print("ğŸ›¡ Detected sensitive areas [\(redactionLabels)]. Redacting...")

                        // å¦‚æœæ˜¯å…¨å±ä¸”æ²¡æœ‰ targetData (å³æ²¡æœ‰è¿›è¡Œè£å‰ªæ‹·è´)ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªæ‹·è´è¿›è¡Œè„±æ•
                        if targetData == nil {
                            let size = Int(CVPixelBufferGetDataSize(pixelBuffer))
                            var copyData = Data(count: size)
                            copyData.withUnsafeMutableBytes { dest in
                                guard let destBase = dest.baseAddress else { return }
                                destBase.copyMemory(from: addr, byteCount: size)
                            }
                            targetData = copyData
                            targetData?.withUnsafeBytes { ptr in
                                if let base = ptr.baseAddress {
                                    targetPtr = UnsafeMutableRawPointer(mutating: base)
                                }
                            }
                        }

                        // æ‰§è¡Œç‰©ç†è„±æ• (é®ç›–åƒç´ )
                        let rawPtr = UnsafeMutableRawPointer(targetPtr)
                        let mutablePtr = rawPtr.assumingMemoryBound(to: UInt8.self)

                        // å…³é”®ä¿®å¤ï¼šä¼ å…¥æ­£ç¡®çš„ bytesPerRow
                        // å¦‚æœæ˜¯æ–°åˆ†é…çš„ targetDataï¼Œåˆ™ä½¿ç”¨ç´§å‡‘çš„ width * 4
                        // å¦‚æœæ˜¯ç›´æ¥æ“ä½œæˆ–æ‹·è´çš„ pixelBuffer æ•°æ®ï¼Œåˆ™ä½¿ç”¨åŸ buffer çš„ bytesPerRow
                        let effectiveBytesPerRow = (targetData != nil && windowInfo != nil) ? (Int(targetWidth) * 4) : bytesPerRow

                        ImageRedactor.redact(
                            ptr: mutablePtr,
                            width: Int(targetWidth),
                            height: Int(targetHeight),
                            bytesPerRow: effectiveBytesPerRow,
                            targets: targets
                        )
                    }
                }

                let recognizedStrings = observations.compactMap { $0.topCandidates(1).first?.string }
                let rawOcrText = recognizedStrings.joined(separator: " ")
                ocrText = redactionEnabled ? SensitiveInfoDetector.redactText(rawOcrText, keywords: sensitiveKeywords) : rawOcrText
            }
        } catch {
            print("âš ï¸ OCR failed: \(error)")
        }

        // 3. è®¡ç®—æ•°æ®é•¿åº¦
        let totalBytes = (targetData != nil) ? targetData!.count : CVPixelBufferGetDataSize(pixelBuffer)

        print("ğŸ“¸ Capture [\(captureType)] frame: \(targetWidth)x\(targetHeight), OCR len: \(ocrText.count), sensitive: \(isSensitiveFrame) [\(redactionLabels)]")

        // 4. è·å–å½“å‰æœ€å‰ç«¯çš„åº”ç”¨åç§°
        let frontAppName = NSWorkspace.shared.frontmostApplication?.localizedName ?? "Unknown"

        // 5. è°ƒç”¨ FFI
        let appNameWithType = "\(frontAppName)[\(captureType)]"

        ocrText.withCString { ocrPtr in
            appNameWithType.withCString { appNamePtr in
                redactionLabels.withCString { labelsPtr in
                    rust_analyze_enhanced_image(
                        targetPtr.assumingMemoryBound(to: UInt8.self),
                        Int(totalBytes),
                        targetWidth,
                        targetHeight,
                        appNamePtr,
                        isSensitiveFrame,
                        ocrPtr,
                        labelsPtr
                    )
                }
            }
        }
    }
}
